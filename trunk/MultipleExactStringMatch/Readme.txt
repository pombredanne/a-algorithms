I have decided that I will produce multiple patterns exact string matching algorithm based on a simple string hash function. My algorithm is provided in HashingStringMatch.cs. Every token in the English alphabet gets a code which is an unsigned int 32 random number. Hashes are unsigned 64 bit numbers so that they can hold a computation based on 32 bit unsigned numbers. Random codes give us very low probability that patterns with different tokens will produce the same hash. Patterns which contain the same tokens, but in different order (permutations) will produce the same hash, because of the nature of the hash function. The hash function is simply the sum of all codes.

The idea of the algorithm is to keep a temp hash which at some point will match the hash of the pattern we are searching for. This is done by moving a hash “window” over the text. For each element we are adding it (its code) to the temp hash and then subtracting the first element in the temp hash. This allows for a very easy to compute hash function. When we find that a temp hash matches the hash of a pattern (or patterns in this case) then an old fashioned .NET string comparison is done. My algorithm supports an array of patterns to check by keeping the length of each pattern and also keeping a temp hash for each pattern while iterating over the text. Complexity should be more than O(k+n) where k is the number of patterns. The algorithm can be further optimized.

By checking on the Internet I found that the Aho–Corasick is one of the best algorithms for multi-pattern exact string matching. It also visits each token just once. The complexity of the algorithm is linear in the length of the patterns plus the length of the searched text plus the number of output matches. It seems like the algorithm is building a kind of an automation. Automata is well studied field in Mathematics. So to me it seems that the Aho–Corasick is the state of the art algorithm (at least one of the best).

My code in file TestApp.cs tests both algorithms and shows that my hashing algorithm is orders of magnitude slower than Aho–Corasick. Tests are synthetic, so it will be interesting to see how it works on real world articles. Both algorithms do precomputing over the patterns rather than the text. The thing is that the Aho–Corasick algorithm is able to cut wrong paths in much earlier stages.